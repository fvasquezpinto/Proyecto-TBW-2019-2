{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis de sentimiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este notebook contiene modelos de análisis de sentimiento para páginas de reviews de películas: IMDB para el idioma inglés, y filmaffinity para el idioma español."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Función para leer los datos.\n",
    "def readDataIMDB(inputSize):\n",
    "    data = []\n",
    "    for file in range(1, inputSize + 1):\n",
    "        for line in open(\"Datasets scrapeados/IMDb_reviews_0\" + str(file)+ \"_03_2020.txt\", 'r', encoding = 'latin'):\n",
    "            splitedLine = line.split(';', maxsplit=1)\n",
    "            clasification = int(splitedLine[0])\n",
    "            if clasification >= 1 and clasification <= 4:\n",
    "                clasification = 0\n",
    "            elif clasification == 5 or clasification == 6:\n",
    "                clasification = 1\n",
    "            else:\n",
    "                clasification = 2\n",
    "            data.append([splitedLine[1], clasification])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Lectura de los datos.\n",
    "dataFrame = pd.DataFrame(readDataIMDB(7), columns=['review', 'calification'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>calification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It's not really a review but my attempt to exp...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I am remarkably stingy with my 10/10 ratings. ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I can't remember the last time I saw a movie t...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This movie is a gosh darn masterpiece. It will...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Parasite was directed and written by Bong Joon...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  calification\n",
       "0  It's not really a review but my attempt to exp...             2\n",
       "1  I am remarkably stingy with my 10/10 ratings. ...             2\n",
       "2  I can't remember the last time I saw a movie t...             2\n",
       "3  This movie is a gosh darn masterpiece. It will...             2\n",
       "4  Parasite was directed and written by Bong Joon...             2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataFrame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Quitar puntos y otros signos de puntuación.\n",
    "REPLACE_NO_SPACE = re.compile(\"[.;:!\\'?,\\\"()\\[\\]]\")\n",
    "REPLACE_WITH_SPACE = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")\n",
    "\n",
    "def preprocess_reviews(reviews):\n",
    "    reviews = [REPLACE_NO_SPACE.sub(\"\", line.lower()) for line in reviews]\n",
    "    reviews = [REPLACE_WITH_SPACE.sub(\" \", line) for line in reviews]\n",
    "    \n",
    "    return reviews\n",
    "\n",
    "dataFrame['review_clean'] = dataFrame['review'].apply(lambda review: REPLACE_NO_SPACE.sub(\"\", review.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "dataFrame['review_clean'] = dataFrame['review_clean'].apply(lambda review: REPLACE_WITH_SPACE.sub(\" \", review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>calification</th>\n",
       "      <th>review_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It's not really a review but my attempt to exp...</td>\n",
       "      <td>2</td>\n",
       "      <td>its not really a review but my attempt to expl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I am remarkably stingy with my 10/10 ratings. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>i am remarkably stingy with my 10 10 ratings i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I can't remember the last time I saw a movie t...</td>\n",
       "      <td>2</td>\n",
       "      <td>i cant remember the last time i saw a movie th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This movie is a gosh darn masterpiece. It will...</td>\n",
       "      <td>2</td>\n",
       "      <td>this movie is a gosh darn masterpiece it will ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Parasite was directed and written by Bong Joon...</td>\n",
       "      <td>2</td>\n",
       "      <td>parasite was directed and written by bong joon...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  calification  \\\n",
       "0  It's not really a review but my attempt to exp...             2   \n",
       "1  I am remarkably stingy with my 10/10 ratings. ...             2   \n",
       "2  I can't remember the last time I saw a movie t...             2   \n",
       "3  This movie is a gosh darn masterpiece. It will...             2   \n",
       "4  Parasite was directed and written by Bong Joon...             2   \n",
       "\n",
       "                                        review_clean  \n",
       "0  its not really a review but my attempt to expl...  \n",
       "1  i am remarkably stingy with my 10 10 ratings i...  \n",
       "2  i cant remember the last time i saw a movie th...  \n",
       "3  this movie is a gosh darn masterpiece it will ...  \n",
       "4  parasite was directed and written by bong joon...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataFrame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Recordar: remover todas las stopwords puede no ser tan beneficioso,\n",
    "# por lo que se puede generar una lista de stopwords definida por nosotros.\n",
    "\n",
    "# Se eliminan las stops words porque generalmente mejoran el entrenamiento.\n",
    "english_stop_words = stopwords.words('english')\n",
    "\n",
    "#dataFrame['review'].apply(lambda x: [item for item in x if item not in english_stop_words])\n",
    "dataFrame['review_without_stop'] = dataFrame['review_clean'].apply(lambda x: ' '.join([word for word in x.split() if word not in (english_stop_words)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>calification</th>\n",
       "      <th>review_clean</th>\n",
       "      <th>review_without_stop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It's not really a review but my attempt to exp...</td>\n",
       "      <td>2</td>\n",
       "      <td>its not really a review but my attempt to expl...</td>\n",
       "      <td>really review attempt explain interpreted movi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I am remarkably stingy with my 10/10 ratings. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>i am remarkably stingy with my 10 10 ratings i...</td>\n",
       "      <td>remarkably stingy 10 10 ratings ill first pers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I can't remember the last time I saw a movie t...</td>\n",
       "      <td>2</td>\n",
       "      <td>i cant remember the last time i saw a movie th...</td>\n",
       "      <td>cant remember last time saw movie contained ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This movie is a gosh darn masterpiece. It will...</td>\n",
       "      <td>2</td>\n",
       "      <td>this movie is a gosh darn masterpiece it will ...</td>\n",
       "      <td>movie gosh darn masterpiece make belly laugh c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Parasite was directed and written by Bong Joon...</td>\n",
       "      <td>2</td>\n",
       "      <td>parasite was directed and written by bong joon...</td>\n",
       "      <td>parasite directed written bong joon ho tells s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  calification  \\\n",
       "0  It's not really a review but my attempt to exp...             2   \n",
       "1  I am remarkably stingy with my 10/10 ratings. ...             2   \n",
       "2  I can't remember the last time I saw a movie t...             2   \n",
       "3  This movie is a gosh darn masterpiece. It will...             2   \n",
       "4  Parasite was directed and written by Bong Joon...             2   \n",
       "\n",
       "                                        review_clean  \\\n",
       "0  its not really a review but my attempt to expl...   \n",
       "1  i am remarkably stingy with my 10 10 ratings i...   \n",
       "2  i cant remember the last time i saw a movie th...   \n",
       "3  this movie is a gosh darn masterpiece it will ...   \n",
       "4  parasite was directed and written by bong joon...   \n",
       "\n",
       "                                 review_without_stop  \n",
       "0  really review attempt explain interpreted movi...  \n",
       "1  remarkably stingy 10 10 ratings ill first pers...  \n",
       "2  cant remember last time saw movie contained ma...  \n",
       "3  movie gosh darn masterpiece make belly laugh c...  \n",
       "4  parasite directed written bong joon ho tells s...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataFrame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Lematizar\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import wordnet\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Para que funcione el lemmatizador, debemos indicar que tipo de palabras es.\n",
    "# Esta función indica que tipo de palabra es.\n",
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "\n",
    "    return tag_dict.get(tag, wordnet.NOUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'stingy'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize('stingy', get_wordnet_pos('stingy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "dataFrame['review_lemmatized'] = dataFrame['review_without_stop'].apply(lambda x: ' '.join([lemmatizer.lemmatize(word, get_wordnet_pos(word)) for word in x.split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>calification</th>\n",
       "      <th>review_clean</th>\n",
       "      <th>review_without_stop</th>\n",
       "      <th>review_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It's not really a review but my attempt to exp...</td>\n",
       "      <td>2</td>\n",
       "      <td>its not really a review but my attempt to expl...</td>\n",
       "      <td>really review attempt explain interpreted movi...</td>\n",
       "      <td>really review attempt explain interpret movie ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I am remarkably stingy with my 10/10 ratings. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>i am remarkably stingy with my 10 10 ratings i...</td>\n",
       "      <td>remarkably stingy 10 10 ratings ill first pers...</td>\n",
       "      <td>remarkably stingy 10 10 rating ill first perso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I can't remember the last time I saw a movie t...</td>\n",
       "      <td>2</td>\n",
       "      <td>i cant remember the last time i saw a movie th...</td>\n",
       "      <td>cant remember last time saw movie contained ma...</td>\n",
       "      <td>cant remember last time saw movie contain many...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This movie is a gosh darn masterpiece. It will...</td>\n",
       "      <td>2</td>\n",
       "      <td>this movie is a gosh darn masterpiece it will ...</td>\n",
       "      <td>movie gosh darn masterpiece make belly laugh c...</td>\n",
       "      <td>movie gosh darn masterpiece make belly laugh c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Parasite was directed and written by Bong Joon...</td>\n",
       "      <td>2</td>\n",
       "      <td>parasite was directed and written by bong joon...</td>\n",
       "      <td>parasite directed written bong joon ho tells s...</td>\n",
       "      <td>parasite direct write bong joon ho tell story ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  calification  \\\n",
       "0  It's not really a review but my attempt to exp...             2   \n",
       "1  I am remarkably stingy with my 10/10 ratings. ...             2   \n",
       "2  I can't remember the last time I saw a movie t...             2   \n",
       "3  This movie is a gosh darn masterpiece. It will...             2   \n",
       "4  Parasite was directed and written by Bong Joon...             2   \n",
       "\n",
       "                                        review_clean  \\\n",
       "0  its not really a review but my attempt to expl...   \n",
       "1  i am remarkably stingy with my 10 10 ratings i...   \n",
       "2  i cant remember the last time i saw a movie th...   \n",
       "3  this movie is a gosh darn masterpiece it will ...   \n",
       "4  parasite was directed and written by bong joon...   \n",
       "\n",
       "                                 review_without_stop  \\\n",
       "0  really review attempt explain interpreted movi...   \n",
       "1  remarkably stingy 10 10 ratings ill first pers...   \n",
       "2  cant remember last time saw movie contained ma...   \n",
       "3  movie gosh darn masterpiece make belly laugh c...   \n",
       "4  parasite directed written bong joon ho tells s...   \n",
       "\n",
       "                                   review_lemmatized  \n",
       "0  really review attempt explain interpret movie ...  \n",
       "1  remarkably stingy 10 10 rating ill first perso...  \n",
       "2  cant remember last time saw movie contain many...  \n",
       "3  movie gosh darn masterpiece make belly laugh c...  \n",
       "4  parasite direct write bong joon ho tell story ...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataFrame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "dataFrame['review_stemmed'] = dataFrame['review_without_stop'].apply(lambda x: ' '.join([stemmer.stem(word) for word in x.split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#dataFrame.to_csv('datoslimpios.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se cargan los datos ya procesados. Estos toman bastante tiempo en procesar, principalmente el lematizar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lectura de los datos ya trabajados.\n",
    "dataFrame = pd.read_csv('datoslimpios.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>calification</th>\n",
       "      <th>review_clean</th>\n",
       "      <th>review_without_stop</th>\n",
       "      <th>review_lemmatized</th>\n",
       "      <th>review_stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>87259</td>\n",
       "      <td>2</td>\n",
       "      <td>this is one of the masterpiece bengali movie i...</td>\n",
       "      <td>one masterpiece bengali movie didnt bored sing...</td>\n",
       "      <td>one masterpiece bengali movie didnt bore singl...</td>\n",
       "      <td>one masterpiec bengali movi didnt bore singl m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45630</td>\n",
       "      <td>1</td>\n",
       "      <td>honneponnetje is a completely meaningless but ...</td>\n",
       "      <td>honneponnetje completely meaningless entertain...</td>\n",
       "      <td>honneponnetje completely meaningless entertain...</td>\n",
       "      <td>honneponnetj complet meaningless entertain 80 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>133723</td>\n",
       "      <td>2</td>\n",
       "      <td>we see a family that gradually starts to feed ...</td>\n",
       "      <td>see family gradually starts feed privileged fa...</td>\n",
       "      <td>see family gradually start feed privileged fam...</td>\n",
       "      <td>see famili gradual start feed privileg famili ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67367</td>\n",
       "      <td>2</td>\n",
       "      <td>i saw dirty mary at the venice beach film fest...</td>\n",
       "      <td>saw dirty mary venice beach film festival love...</td>\n",
       "      <td>saw dirty mary venice beach film festival love...</td>\n",
       "      <td>saw dirti mari venic beach film festiv love am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6868</td>\n",
       "      <td>2</td>\n",
       "      <td>masculin feminin is a definitive example of fr...</td>\n",
       "      <td>masculin feminin definitive example french new...</td>\n",
       "      <td>masculin feminin definitive example french new...</td>\n",
       "      <td>masculin feminin definit exampl french new wav...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  calification  \\\n",
       "0       87259             2   \n",
       "1       45630             1   \n",
       "2      133723             2   \n",
       "3       67367             2   \n",
       "4        6868             2   \n",
       "\n",
       "                                        review_clean  \\\n",
       "0  this is one of the masterpiece bengali movie i...   \n",
       "1  honneponnetje is a completely meaningless but ...   \n",
       "2  we see a family that gradually starts to feed ...   \n",
       "3  i saw dirty mary at the venice beach film fest...   \n",
       "4  masculin feminin is a definitive example of fr...   \n",
       "\n",
       "                                 review_without_stop  \\\n",
       "0  one masterpiece bengali movie didnt bored sing...   \n",
       "1  honneponnetje completely meaningless entertain...   \n",
       "2  see family gradually starts feed privileged fa...   \n",
       "3  saw dirty mary venice beach film festival love...   \n",
       "4  masculin feminin definitive example french new...   \n",
       "\n",
       "                                   review_lemmatized  \\\n",
       "0  one masterpiece bengali movie didnt bore singl...   \n",
       "1  honneponnetje completely meaningless entertain...   \n",
       "2  see family gradually start feed privileged fam...   \n",
       "3  saw dirty mary venice beach film festival love...   \n",
       "4  masculin feminin definitive example french new...   \n",
       "\n",
       "                                      review_stemmed  \n",
       "0  one masterpiec bengali movi didnt bore singl m...  \n",
       "1  honneponnetj complet meaningless entertain 80 ...  \n",
       "2  see famili gradual start feed privileg famili ...  \n",
       "3  saw dirti mari venic beach film festiv love am...  \n",
       "4  masculin feminin definit exampl french new wav...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataFrame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataFrame.drop(columns=['Unnamed: 0'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se define una semilla para poder replicar los resultados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El conjunto de datos es muy grande, esto implica que posiblemente la memoria del computador no sea suficiente. Por lo tanto, se decide tomar una muestra aleatoria de 50.000 datos para realizar el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataFrame = dataFrame.sample(50000, random_state= seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De estos, 40.000 serán usados para el entrenamiento y 10.000 para el conjunto de pruebas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se genera un conjunto de entrenamiento, validación y de pruebas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFrameTrain = dataFrame[0:40000]\n",
    "dataFrameTest = dataFrame[40000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Definir el conjunto de datos para entrenar. \n",
    "# Primero se utilizará el conjunto de datos sin stopwords pero sin otro preprocesamiento.\n",
    "X = dataFrameTrain['review_without_stop']\n",
    "y = dataFrameTrain['calification']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se utiliza un modelo de regresión logística."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.824\n",
      "Accuracy for C=0.05: 0.83125\n",
      "Accuracy for C=0.25: 0.833375\n",
      "Accuracy for C=0.5: 0.8335\n",
      "Accuracy for C=1: 0.833\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "ngram_vectorizer = CountVectorizer(binary=True, ngram_range=(1, 2))\n",
    "ngram_vectorizer.fit(X)\n",
    "X = ngram_vectorizer.transform(X)\n",
    "target = y\n",
    "# Separamos en conjunto de prueba y entrenamiento.\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, target, train_size = 0.80, random_state = seed)\n",
    "\n",
    "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "    lr = LogisticRegression(C=c, max_iter=200, random_state=3, solver = 'lbfgs')\n",
    "    lr.fit(X_train, y_train)\n",
    "    print (\"Accuracy for C=%s: %s\" \n",
    "           % (c, accuracy_score(y_val, lr.predict(X_val))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego, se entrena con el conjunto lematizado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir el conjunto de datos para entrenar. En este caso, lematizado.\n",
    "X = dataFrameTrain['review_lemmatized']\n",
    "y = dataFrameTrain['calification']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.822875\n",
      "Accuracy for C=0.05: 0.834375\n",
      "Accuracy for C=0.25: 0.834875\n",
      "Accuracy for C=0.5: 0.8355\n",
      "Accuracy for C=1: 0.835375\n"
     ]
    }
   ],
   "source": [
    "ngram_vectorizer = CountVectorizer(binary=True, ngram_range=(1, 2))\n",
    "ngram_vectorizer.fit(X)\n",
    "X = ngram_vectorizer.transform(X)\n",
    "target = y\n",
    "# Separamos en conjunto de prueba y entrenamiento.\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, target, train_size = 0.80, random_state = seed)\n",
    "\n",
    "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "    lr = LogisticRegression(C=c, max_iter=200, random_state = seed, solver = 'lbfgs')\n",
    "    lr.fit(X_train, y_train)\n",
    "    print (\"Accuracy for C=%s: %s\" \n",
    "           % (c, accuracy_score(y_val, lr.predict(X_val))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, se entrena el modelo con stemming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir el conjunto de datos para entrenar. En este caso, con stemming.\n",
    "X = dataFrameTrain['review_stemmed']\n",
    "y = dataFrameTrain['calification']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.824\n",
      "Accuracy for C=0.05: 0.835\n",
      "Accuracy for C=0.25: 0.833\n",
      "Accuracy for C=0.5: 0.83325\n",
      "Accuracy for C=1: 0.83375\n"
     ]
    }
   ],
   "source": [
    "ngram_vectorizer = CountVectorizer(binary=True, ngram_range=(1, 2))\n",
    "ngram_vectorizer.fit(X)\n",
    "X = ngram_vectorizer.transform(X)\n",
    "target = y\n",
    "# Separamos en conjunto de prueba y entrenamiento.\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, target, train_size = 0.80, random_state = seed)\n",
    "\n",
    "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "    lr = LogisticRegression(C=c, max_iter=200, solver = 'lbfgs', random_state = seed)\n",
    "    lr.fit(X_train, y_train)\n",
    "    print (\"Accuracy for C=%s: %s\" \n",
    "           % (c, accuracy_score(y_val, lr.predict(X_val))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el modelo de regresión logística, se obtiene que los mejores resultados se logran al lematizar las palabras con un valor de C igual a 0.5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definiendo el modelo final:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=True, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram_vectorizer = CountVectorizer(binary=True, ngram_range=(1, 2))\n",
    "ngram_vectorizer.fit(dataFrame['review_lemmatized'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ngram_vectorizer.transform(dataFrame['review_lemmatized'])\n",
    "y = dataFrame['calification']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[0:40000]\n",
    "y_train = y[0:40000]\n",
    "X_test = X[40000:]\n",
    "y_test = y[40000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=1: 0.8382\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(C=0.5, max_iter=200, solver = 'lbfgs', random_state = seed)\n",
    "lr.fit(X_train, y_train)\n",
    "print (\"Accuracy for C=%s: %s\" \n",
    "       % (c, accuracy_score(y_test, lr.predict(X_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filmaffinity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para leer los datos.\n",
    "def readDataFilmaffinity():\n",
    "    data = []\n",
    "    for file in range(7, 9):\n",
    "        for line in open(\"Filmaffinity/filmaffinity_reviews_0\" + str(file) + \"_03_2020.txt\", 'r', encoding = 'utf8'):\n",
    "            splitedLine = line.split(';', maxsplit=1)\n",
    "            clasification = int(splitedLine[0])\n",
    "            if clasification >= 1 and clasification <= 4:\n",
    "                clasification = 0\n",
    "            elif clasification == 5 or clasification == 6:\n",
    "                clasification = 1\n",
    "            else:\n",
    "                clasification = 2\n",
    "            data.append([splitedLine[1], clasification])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lectura de los datos.\n",
    "dataFrame = pd.DataFrame(readDataFilmaffinity(), columns=['review', 'calification'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>calification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pensé que iba a tratarse de otro telefilm conv...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>La verdad, no sé qué espera la gente cuando ve...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>La peli tiene un humor bastante poco \"correcto...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Origen\" no es lo mismo que \"Torrente 2\". Ni \"...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Me reí mucho viendo a Ben Stiller, vaya crack....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  calification\n",
       "0  Pensé que iba a tratarse de otro telefilm conv...             1\n",
       "1  La verdad, no sé qué espera la gente cuando ve...             1\n",
       "2  La peli tiene un humor bastante poco \"correcto...             2\n",
       "3  \"Origen\" no es lo mismo que \"Torrente 2\". Ni \"...             2\n",
       "4  Me reí mucho viendo a Ben Stiller, vaya crack....             1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataFrame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quitar puntos y otros signos de puntuación.\n",
    "REPLACE_NO_SPACE = re.compile(\"[.;:!\\'?,\\\"()\\[\\]]\")\n",
    "REPLACE_WITH_SPACE = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")\n",
    "\n",
    "def preprocess_reviews(reviews):\n",
    "    reviews = [REPLACE_NO_SPACE.sub(\"\", line.lower()) for line in reviews]\n",
    "    reviews = [REPLACE_WITH_SPACE.sub(\" \", line) for line in reviews]\n",
    "    \n",
    "    return reviews\n",
    "\n",
    "dataFrame['review_clean'] = dataFrame['review'].apply(lambda review: REPLACE_NO_SPACE.sub(\"\", review.lower()))\n",
    "dataFrame['review_clean'] = dataFrame['review_clean'].apply(lambda review: REPLACE_WITH_SPACE.sub(\" \", review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se quitan los tildes.\n",
    "dataFrame['review_clean'] = dataFrame['review_clean'].str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se eliminan las stops words porque generalmente mejoran el entrenamiento.\n",
    "spanish_stop_words = stopwords.words('spanish')\n",
    "\n",
    "dataFrame['review_without_stop'] = dataFrame['review_clean'].apply(lambda x: ' '.join([word for word in x.split() if word not in (spanish_stop_words)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import SnowballStemmer\n",
    "spanishstemmer=SnowballStemmer(\"spanish\")\n",
    "\n",
    "dataFrame['review_stemmed'] = dataFrame['review_without_stop'].apply(lambda x: ' '.join([spanishstemmer.stem(word) for word in x.split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>calification</th>\n",
       "      <th>review_clean</th>\n",
       "      <th>review_without_stop</th>\n",
       "      <th>review_stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pensé que iba a tratarse de otro telefilm conv...</td>\n",
       "      <td>1</td>\n",
       "      <td>pense que iba a tratarse de otro telefilm conv...</td>\n",
       "      <td>pense iba tratarse telefilm convencional solo ...</td>\n",
       "      <td>pens iba trat telefilm convencional sol salv p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>La verdad, no sé qué espera la gente cuando ve...</td>\n",
       "      <td>1</td>\n",
       "      <td>la verdad no se que espera la gente cuando ve ...</td>\n",
       "      <td>verdad espera gente ve peli dos horas guiones ...</td>\n",
       "      <td>verd esper gent ve peli dos hor guion sup curr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>La peli tiene un humor bastante poco \"correcto...</td>\n",
       "      <td>2</td>\n",
       "      <td>la peli tiene un humor bastante poco correcto ...</td>\n",
       "      <td>peli humor bastante correcto tiempos corren pa...</td>\n",
       "      <td>peli humor bastant correct tiemp corr par reir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Origen\" no es lo mismo que \"Torrente 2\". Ni \"...</td>\n",
       "      <td>2</td>\n",
       "      <td>origen no es lo mismo que torrente 2 ni gladia...</td>\n",
       "      <td>origen mismo torrente 2 gladiator mismo estupi...</td>\n",
       "      <td>orig mism torrent 2 gladiator mism estup pelic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Me reí mucho viendo a Ben Stiller, vaya crack....</td>\n",
       "      <td>1</td>\n",
       "      <td>me rei mucho viendo a ben stiller vaya crack l...</td>\n",
       "      <td>rei viendo ben stiller vaya crack peli momento...</td>\n",
       "      <td>rei viend ben still vay crack peli moment absu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  calification  \\\n",
       "0  Pensé que iba a tratarse de otro telefilm conv...             1   \n",
       "1  La verdad, no sé qué espera la gente cuando ve...             1   \n",
       "2  La peli tiene un humor bastante poco \"correcto...             2   \n",
       "3  \"Origen\" no es lo mismo que \"Torrente 2\". Ni \"...             2   \n",
       "4  Me reí mucho viendo a Ben Stiller, vaya crack....             1   \n",
       "\n",
       "                                        review_clean  \\\n",
       "0  pense que iba a tratarse de otro telefilm conv...   \n",
       "1  la verdad no se que espera la gente cuando ve ...   \n",
       "2  la peli tiene un humor bastante poco correcto ...   \n",
       "3  origen no es lo mismo que torrente 2 ni gladia...   \n",
       "4  me rei mucho viendo a ben stiller vaya crack l...   \n",
       "\n",
       "                                 review_without_stop  \\\n",
       "0  pense iba tratarse telefilm convencional solo ...   \n",
       "1  verdad espera gente ve peli dos horas guiones ...   \n",
       "2  peli humor bastante correcto tiempos corren pa...   \n",
       "3  origen mismo torrente 2 gladiator mismo estupi...   \n",
       "4  rei viendo ben stiller vaya crack peli momento...   \n",
       "\n",
       "                                      review_stemmed  \n",
       "0  pens iba trat telefilm convencional sol salv p...  \n",
       "1  verd esper gent ve peli dos hor guion sup curr...  \n",
       "2  peli humor bastant correct tiemp corr par reir...  \n",
       "3  orig mism torrent 2 gladiator mism estup pelic...  \n",
       "4  rei viend ben still vay crack peli moment absu...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataFrame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataFrame.to_csv('datoslimpiosFilmaffinity.csv')\n",
    "dataFrame = pd.read_csv('datoslimpiosFilmaffinity.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se replica lo hecho en el modelo para reviews en inglés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFrame = dataFrame.sample(50000, random_state= seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFrameTrain = dataFrame[0:40000]\n",
    "dataFrameTest = dataFrame[40000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir el conjunto de datos para entrenar. \n",
    "# Primero se utilizará el conjunto de datos sin stopwords pero sin otro preprocesamiento.\n",
    "X = dataFrameTrain['review_without_stop']\n",
    "y = dataFrameTrain['calification']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.794\n",
      "Accuracy for C=0.05: 0.805125\n",
      "Accuracy for C=0.25: 0.805375\n",
      "Accuracy for C=0.5: 0.805875\n",
      "Accuracy for C=1: 0.80525\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "ngram_vectorizer = CountVectorizer(binary=True, ngram_range=(1, 2))\n",
    "ngram_vectorizer.fit(X)\n",
    "X = ngram_vectorizer.transform(X)\n",
    "target = y\n",
    "# Separamos en conjunto de prueba y entrenamiento.\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, target, train_size = 0.80, random_state = seed)\n",
    "\n",
    "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "    lr = LogisticRegression(C=c, max_iter=200, random_state=3, solver = 'lbfgs')\n",
    "    lr.fit(X_train, y_train)\n",
    "    print (\"Accuracy for C=%s: %s\" \n",
    "           % (c, accuracy_score(y_val, lr.predict(X_val))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir el conjunto de datos para entrenar. En este caso, con stemming.\n",
    "X = dataFrameTrain['review_stemmed']\n",
    "y = dataFrameTrain['calification']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.79625\n",
      "Accuracy for C=0.05: 0.809\n",
      "Accuracy for C=0.25: 0.8075\n",
      "Accuracy for C=0.5: 0.807875\n",
      "Accuracy for C=1: 0.80675\n"
     ]
    }
   ],
   "source": [
    "ngram_vectorizer = CountVectorizer(binary=True, ngram_range=(1, 2))\n",
    "ngram_vectorizer.fit(X)\n",
    "X = ngram_vectorizer.transform(X)\n",
    "target = y\n",
    "# Separamos en conjunto de prueba y entrenamiento.\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, target, train_size = 0.80, random_state = seed)\n",
    "\n",
    "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "    lr = LogisticRegression(C=c, max_iter=200, solver = 'lbfgs', random_state = seed)\n",
    "    lr.fit(X_train, y_train)\n",
    "    print (\"Accuracy for C=%s: %s\" \n",
    "           % (c, accuracy_score(y_val, lr.predict(X_val))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el conjunto de reviews en español, el mejor valor de C fue 0.05 para el conjunto stemmed. Con esto se genera el modelo final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=True, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram_vectorizer = CountVectorizer(binary=True, ngram_range=(1, 2))\n",
    "ngram_vectorizer.fit(dataFrame['review_stemmed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ngram_vectorizer.transform(dataFrame['review_stemmed'])\n",
    "y = dataFrame['calification']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[0:40000]\n",
    "y_train = y[0:40000]\n",
    "X_test = X[40000:]\n",
    "y_test = y[40000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.05: 0.8072\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(C=0.05, max_iter=200, solver = 'lbfgs', random_state = seed)\n",
    "lr.fit(X_train, y_train)\n",
    "print (\"Accuracy for C=%s: %s\" \n",
    "       % (0.05, accuracy_score(y_test, lr.predict(X_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En los modelos anteriores se aplicó un modelo de regresión logística. Podemos probar si otro modelo podría realizar un mejor desempeño. En este caso, se decide probar con random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier as RFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataFrame['review_without_stop']\n",
    "y = dataFrame['calification']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=10: 0.7906\n",
      "Accuracy for C=30: 0.7852\n",
      "Accuracy for C=50: 0.7834\n",
      "Accuracy for C=100: 0.7842\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-061da41494ed>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRFC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     print (\"Accuracy for C=%s: %s\" \n\u001b[0;32m     13\u001b[0m            % (n, accuracy_score(y_val, model.predict(X_val))))\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\MachineLearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    381\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m                     n_samples_bootstrap=n_samples_bootstrap)\n\u001b[1;32m--> 383\u001b[1;33m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[0;32m    384\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    385\u001b[0m             \u001b[1;31m# Collect newly grown trees\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\MachineLearning\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1005\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1007\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1008\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1009\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\MachineLearning\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    833\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    834\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 835\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    836\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    837\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\MachineLearning\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    752\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 754\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    755\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\MachineLearning\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    207\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 209\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    210\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\MachineLearning\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    588\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    589\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 590\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    591\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\MachineLearning\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 256\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\MachineLearning\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 256\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\MachineLearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    163\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'balanced'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 165\u001b[1;33m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    166\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\MachineLearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    875\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    876\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 877\u001b[1;33m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[0;32m    878\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\MachineLearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    365\u001b[0m                                            min_impurity_split)\n\u001b[0;32m    366\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 367\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    368\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    369\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ngram_vectorizer = CountVectorizer(binary=True, ngram_range=(1, 2))\n",
    "ngram_vectorizer.fit(X)\n",
    "X = ngram_vectorizer.transform(X)\n",
    "target = y\n",
    "# Separamos en conjunto de prueba y entrenamiento.\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, target, train_size = 0.80)\n",
    "\n",
    "for n in [10, 30, 50, 100, 200]:\n",
    "    \n",
    "    model = RFC(n_estimators=n)\n",
    "    model.fit(X_train, y_train)\n",
    "    print (\"Accuracy for C=%s: %s\" \n",
    "           % (n, accuracy_score(y_val, model.predict(X_val))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
